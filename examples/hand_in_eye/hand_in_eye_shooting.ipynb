{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda hostname/IP and Desk login information of your robot\n",
    "hostname = '169.254.37.13'\n",
    "username = 'admin'\n",
    "password = 'admin1234'\n",
    "\n",
    "# panda-py is chatty, activate information log level\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:desk:Login succesful.\n",
      "INFO:desk:Retaken control.\n"
     ]
    }
   ],
   "source": [
    "import panda_py\n",
    "\n",
    "desk = panda_py.Desk(hostname, username, password, platform='fr3')\n",
    "desk.unlock()\n",
    "desk.activate_fci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Connected to robot (169.254.37.13).\n"
     ]
    }
   ],
   "source": [
    "from panda_py import libfranka\n",
    "\n",
    "panda = panda_py.Panda(hostname)\n",
    "gripper = libfranka.Gripper(hostname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand in eye calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from panda_py import constants\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_move_to_pose(init_pose, roll, pitch, yaw, z_add, x_add, y_add, max_roll_deviation, max_pitch_deviation, max_yaw_deviation):\n",
    "    \"\"\"Generate a new pose with turbulence and move the robot arm to it.\"\"\"\n",
    "    roll_turbulent = roll + np.random.uniform(-max_roll_deviation, max_roll_deviation)\n",
    "    pitch_turbulent = pitch + np.random.uniform(-max_pitch_deviation, max_pitch_deviation)\n",
    "    yaw_turbulent = yaw + np.random.uniform(-max_yaw_deviation, max_yaw_deviation)\n",
    "\n",
    "    r = R.from_euler('xyz', [roll_turbulent, pitch_turbulent, yaw_turbulent], degrees=False)\n",
    "    rotation_matrix = r.as_matrix()\n",
    "\n",
    "    absolute_rotation_matrix = np.dot(init_pose[:3, :3], rotation_matrix)\n",
    "\n",
    "    pose = init_pose.copy()\n",
    "    pose[:3, :3] = absolute_rotation_matrix\n",
    "    pose[2, 3] += z_add\n",
    "    pose[0, 3] += x_add\n",
    "    pose[1, 3] += y_add\n",
    "\n",
    "    panda.move_to_pose(pose)\n",
    "    \n",
    "    return pose\n",
    "\n",
    "def save_pose(pose, base_dir, frame_num):\n",
    "    \"\"\"Save the robot arm's pose to a file.\"\"\"\n",
    "    pose_filename = f'{base_dir}/poses/pose_{frame_num}.npy'\n",
    "    np.save(pose_filename, pose)\n",
    "    print(f\"Saved pose to {pose_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "parent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from realsense.realsense import Camera\n",
    "from realsense.realsense import get_devices\n",
    "\n",
    "\n",
    "def capture_images(camera, delay_before_shooting, start_frame, picture_nums, base_dir, init_pose, roll, pitch, yaw, z_add, x_add, y_add,\n",
    "                   max_roll_deviation, max_pitch_deviation, max_yaw_deviation):\n",
    "    \n",
    "    camera.start()\n",
    "    \n",
    "    rgb_intrinsics, rgb_coeffs, depth_intrinsics, depth_coeffs = camera.get_intrinsics_raw()\n",
    "    depth_scale = camera.get_depth_scale()\n",
    "\n",
    "    print(f\"RGB Intrinsics: {rgb_intrinsics}\")\n",
    "    print(f\"RGB Distortion Coefficients: {rgb_coeffs}\")\n",
    "    rgb_intrinsics_path = f'{base_dir}/rgb_intrinsics.npz'\n",
    "    np.savez(rgb_intrinsics_path, fx=rgb_intrinsics.fx, fy=rgb_intrinsics.fy, ppx=rgb_intrinsics.ppx, ppy=rgb_intrinsics.ppy, coeffs=rgb_intrinsics.coeffs)\n",
    "\n",
    "    print(f\"Depth Scale: {depth_scale}\")\n",
    "    print(f\"Depth Intrinsics: {depth_intrinsics}\")\n",
    "    print(f\"Depth Distortion Coefficients: {depth_coeffs}\")\n",
    "    depth_intrinsics_path = f'{base_dir}/depth_intrinsics.npz'\n",
    "    np.savez(depth_intrinsics_path, fx=depth_intrinsics.fx, fy=depth_intrinsics.fy, ppx=depth_intrinsics.ppx, ppy=depth_intrinsics.ppy, coeffs=depth_intrinsics.coeffs, depth_scale=depth_scale)\n",
    "\n",
    "    # drop the first few frames to allow the camera to warm up\n",
    "    _, _ = camera.shoot()  \n",
    "    time.sleep(delay_before_shooting)\n",
    "\n",
    "    for frame_num in range(start_frame, start_frame + picture_nums):  # Capture images at 10 different poses\n",
    "        pose = generate_and_move_to_pose(init_pose, roll, pitch, yaw, z_add, x_add, y_add,\n",
    "                                         max_roll_deviation, max_pitch_deviation, max_yaw_deviation)\n",
    "        rgb_image, depth_image = camera.shoot()\n",
    "        rgb_filename = f'{base_dir}/rgb/{frame_num}.png'\n",
    "        depth_filename = f'{base_dir}/depth/{frame_num}.npy'\n",
    "        plt.imsave(rgb_filename, rgb_image)\n",
    "        np.save(depth_filename, depth_image)\n",
    "        print(f\"Saved {rgb_filename}\")\n",
    "        print(f\"Saved {depth_filename}\")\n",
    "\n",
    "        save_pose(pose, base_dir, frame_num)\n",
    "\n",
    "    panda.move_to_start()\n",
    "        \n",
    "    camera.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device serial numbers: 048122072163\n",
      "RGB Intrinsics: [ 1280x720  p[651.666 365.568]  f[910.623 910.183]  Inverse Brown Conrady [0 0 0 0 0] ]\n",
      "RGB Distortion Coefficients: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Depth Scale: 0.0010000000474974513\n",
      "Depth Intrinsics: [ 1280x720  p[643.511 349.558]  f[633.854 633.854]  Brown Conrady [0 0 0 0 0] ]\n",
      "Depth Distortion Coefficients: [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.61 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n",
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.37 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/0.png\n",
      "Saved ../../hand_in_eye2/depth/0.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_0.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.23 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/1.png\n",
      "Saved ../../hand_in_eye2/depth/1.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.37 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/2.png\n",
      "Saved ../../hand_in_eye2/depth/2.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.40 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/3.png\n",
      "Saved ../../hand_in_eye2/depth/3.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.44 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/4.png\n",
      "Saved ../../hand_in_eye2/depth/4.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.61 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/5.png\n",
      "Saved ../../hand_in_eye2/depth/5.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.58 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/6.png\n",
      "Saved ../../hand_in_eye2/depth/6.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_6.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.57 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/7.png\n",
      "Saved ../../hand_in_eye2/depth/7.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_7.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToPose).\n",
      "INFO:motion:Computed Cartesian trajectory: 1 waypoint, duration 0.38 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/8.png\n",
      "Saved ../../hand_in_eye2/depth/8.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_8.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:panda:Stopping active controller (Trajectory).\n",
      "INFO:panda:Initializing motion generation (moveToJointPosition).\n",
      "INFO:motion:Computed joint trajectory: 1 waypoint, duration 1.84 seconds.\n",
      "INFO:panda:Starting new controller (Trajectory).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../hand_in_eye2/rgb/9.png\n",
      "Saved ../../hand_in_eye2/depth/9.npy\n",
      "Saved pose to ../../hand_in_eye2/poses/pose_9.npy\n",
      "RGB Intrinsics: [ 1280x720  p[651.666 365.568]  f[910.623 910.183]  Inverse Brown Conrady [0 0 0 0 0] ]\n",
      "RGB Distortion Coefficients: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Depth Scale: 0.0010000000474974513\n",
      "Depth Intrinsics: [ 1280x720  p[643.511 349.558]  f[633.854 633.854]  Brown Conrady [0 0 0 0 0] ]\n",
      "Depth Distortion Coefficients: [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Frame didn't arrive within 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Iterate over the list of configurations and capture images\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_configs):\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mcapture_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay_before_shooting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minit_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroll\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpitch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myaw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mz_add\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_add\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_add\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_roll_deviation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_pitch_deviation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_yaw_deviation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mcapture_images\u001b[0;34m(camera, delay_before_shooting, start_frame, picture_nums, base_dir, init_pose, roll, pitch, yaw, z_add, x_add, y_add, max_roll_deviation, max_pitch_deviation, max_yaw_deviation)\u001b[0m\n\u001b[1;32m     26\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(depth_intrinsics_path, fx\u001b[38;5;241m=\u001b[39mdepth_intrinsics\u001b[38;5;241m.\u001b[39mfx, fy\u001b[38;5;241m=\u001b[39mdepth_intrinsics\u001b[38;5;241m.\u001b[39mfy, ppx\u001b[38;5;241m=\u001b[39mdepth_intrinsics\u001b[38;5;241m.\u001b[39mppx, ppy\u001b[38;5;241m=\u001b[39mdepth_intrinsics\u001b[38;5;241m.\u001b[39mppy, coeffs\u001b[38;5;241m=\u001b[39mdepth_intrinsics\u001b[38;5;241m.\u001b[39mcoeffs, depth_scale\u001b[38;5;241m=\u001b[39mdepth_scale)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# drop the first few frames to allow the camera to warm up\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcamera\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshoot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     30\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay_before_shooting)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_frame, start_frame \u001b[38;5;241m+\u001b[39m picture_nums):  \u001b[38;5;66;03m# Capture images at 10 different poses\u001b[39;00m\n",
      "File \u001b[0;32m~/franka_robot/franka_grasp_baseline/realsense/realsense.py:26\u001b[0m, in \u001b[0;36mCamera.shoot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshoot\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     aligned_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign\u001b[38;5;241m.\u001b[39mprocess(frames)\n\u001b[1;32m     28\u001b[0m     color_frame \u001b[38;5;241m=\u001b[39m aligned_frames\u001b[38;5;241m.\u001b[39mget_color_frame()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Frame didn't arrive within 5000"
     ]
    }
   ],
   "source": [
    "base_dir = '../../hand_in_eye2'\n",
    "os.makedirs(f'{base_dir}/rgb', exist_ok=True)\n",
    "os.makedirs(f'{base_dir}/depth', exist_ok=True)\n",
    "os.makedirs(f'{base_dir}/poses', exist_ok=True)\n",
    "# Define a list of configurations\n",
    "image_configs = [\n",
    "    {\n",
    "        'base_dir': '../hand_in_eye2',\n",
    "        'init_pose': panda_py.fk(constants.JOINT_POSITION_START),\n",
    "        'roll': 0.0,\n",
    "        'pitch': 0.2,\n",
    "        'yaw': 0.0,\n",
    "        'z_add': 0.16,\n",
    "        'x_add': 0.12,\n",
    "        'y_add': 0.0,\n",
    "        'max_roll_deviation': 0.1,\n",
    "        'max_pitch_deviation': 0.1,\n",
    "        'max_yaw_deviation': 0.1\n",
    "    },\n",
    "    {\n",
    "        'base_dir': '../hand_in_eye2',\n",
    "        'init_pose': panda_py.fk(constants.JOINT_POSITION_START),\n",
    "        'roll': 0.3,\n",
    "        'pitch': 0.35,\n",
    "        'yaw': 0.0,\n",
    "        'z_add': 0.1,\n",
    "        'x_add': 0.0,\n",
    "        'y_add': -0.25,\n",
    "        'max_roll_deviation': 0.1,\n",
    "        'max_pitch_deviation': 0.1,\n",
    "        'max_yaw_deviation': 0.1\n",
    "    },\n",
    "    {\n",
    "        'base_dir': '../hand_in_eye2',\n",
    "        'init_pose': panda_py.fk(constants.JOINT_POSITION_START),\n",
    "        'roll': -0.25,\n",
    "        'pitch': 0.35,\n",
    "        'yaw': 0.2,\n",
    "        'z_add': 0.12,\n",
    "        'x_add': 0.1,\n",
    "        'y_add': 0.20,\n",
    "        'max_roll_deviation': 0.1,\n",
    "        'max_pitch_deviation': 0.1,\n",
    "        'max_yaw_deviation': 0.1\n",
    "    },\n",
    "    {\n",
    "        'base_dir': '../hand_in_eye2',\n",
    "        'init_pose': panda_py.fk(constants.JOINT_POSITION_START),\n",
    "        'roll': -0.25,\n",
    "        'pitch': 0.2,\n",
    "        'yaw': 0.2,\n",
    "        'z_add': 0.20,\n",
    "        'x_add': 0.11,\n",
    "        'y_add': 0.1,\n",
    "        'max_roll_deviation': 0.1,\n",
    "        'max_pitch_deviation': 0.1,\n",
    "        'max_yaw_deviation': 0.1\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Enumerate connected RealSense cameras\n",
    "device_serials = get_devices()\n",
    "\n",
    "# Print selected device serial numbers\n",
    "print(\"Selected device serial numbers:\", device_serials[0])\n",
    "\n",
    "rgb_resolution = (1280, 720)  # RGB resolution (width, height)\n",
    "depth_resolution = (1280, 720)  # Depth resolution (width, height)\n",
    "\n",
    "camera = Camera(device_serials[0], rgb_resolution, depth_resolution)\n",
    "\n",
    "# Delay before shooting (in seconds)\n",
    "delay_before_shooting = 2.0\n",
    "\n",
    "# Iterate over the list of configurations and capture images\n",
    "for i, config in enumerate(image_configs):\n",
    "    capture_images(camera, delay_before_shooting, 10*i, 10, base_dir, config['init_pose'], config['roll'], config['pitch'], config['yaw'],\n",
    "                   config['z_add'], config['x_add'], config['y_add'], config['max_roll_deviation'],\n",
    "                   config['max_pitch_deviation'], config['max_yaw_deviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# def calculate_trajectory(center, height, radius, each_angle):\n",
    "#     x_center, y_center = center\n",
    "#     # Initialize lists to store coordinates\n",
    "#     x_trajectory = []\n",
    "#     y_trajectory = []\n",
    "#     z_trajectory = []\n",
    "    \n",
    "#     init_pose = panda_py.fk(constants.JOINT_POSITION_START)\n",
    "#     panda.move_to_start()\n",
    "    \n",
    "#     # Calculate trajectory points\n",
    "#     for angle in range(0, 360, each_angle):\n",
    "#         # Convert angle to radians\n",
    "#         angle_rad = math.radians(angle)\n",
    "        \n",
    "#         # Calculate coordinates of point on circle\n",
    "#         x_point = x_center + radius * math.cos(angle_rad)\n",
    "#         y_point = y_center + radius * math.sin(angle_rad)\n",
    "#         z_point = height\n",
    "        \n",
    "#         panda.move_to_start()\n",
    "        \n",
    "#         # Move the robot arm to the calculated point\n",
    "#         pose = init_pose.copy()\n",
    "#         pose[0, 3] = x_point\n",
    "#         pose[1, 3] = y_point\n",
    "#         pose[2, 3] = z_point\n",
    "        \n",
    "#         import roboticstoolbox as rtb\n",
    "#         robot = rtb.models.Panda()\n",
    "#         from spatialmath import SE3\n",
    "#         import transforms3d.euler as euler\n",
    "\n",
    "#         rotation_matrix = pose[:3, :3]\n",
    "#         translation = pose[:3, 3]\n",
    "\n",
    "#         roll, pitch, yaw = euler.mat2euler(rotation_matrix)\n",
    "#         Tep = SE3.Trans(translation) * SE3.RPY([roll, pitch, yaw])\n",
    "#         print(Tep)\n",
    "#         sol = robot.ik_LM(Tep)         # solve IK\n",
    "#         # print(sol)\n",
    "        \n",
    "#         panda.move_to_joint_position(sol[0])\n",
    "        \n",
    "        \n",
    "#         # Append coordinates to trajectory lists\n",
    "#         x_trajectory.append(x_point)\n",
    "#         y_trajectory.append(y_point)\n",
    "#         z_trajectory.append(z_point)\n",
    "    \n",
    "#     return x_trajectory, y_trajectory, z_trajectory\n",
    "\n",
    "# # Example usage:\n",
    "# center = (0.48, 0)\n",
    "# height = 0.5\n",
    "# radius = 0.17\n",
    "# each_angle = 45  # Angle increment in degrees\n",
    "\n",
    "# x_traj, y_traj, z_traj = calculate_trajectory(center, height, radius, each_angle)\n",
    "# print(\"X trajectory:\", x_traj)\n",
    "# print(\"Y trajectory:\", y_traj)\n",
    "# print(\"Z trajectory:\", z_traj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panda.move_to_start()\n",
    "# # init_pose = panda_py.fk(constants.JOINT_POSITION_START)\n",
    "# # print(init_pose)\n",
    "# # panda.move_to_pose(init_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the trajectory xy\n",
    "# plt.plot(x_traj, y_traj)\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# plt.title('XY Trajectory')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "franka_robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
